#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®€å•æµ‹è¯• DeepSeek API æ˜¯å¦æ­£å¸¸å·¥ä½œ
"""
import asyncio
from config.settings import settings
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage


async def test_simple():
    """ç®€å•æµ‹è¯• LLM æ˜¯å¦å·¥ä½œ"""
    print("=== ç®€å•æµ‹è¯• DeepSeek LLM ===")

    try:
        # è·å–é…ç½®
        llm_config = settings.get_llm_config()
        print(f"ä½¿ç”¨æ¨¡å‹: {llm_config.get('model')}")
        print(f"API Base: {llm_config.get('openai_api_base', 'Default')}")

        # åˆå§‹åŒ– LLM
        llm = ChatOpenAI(**llm_config)

        # å‘é€æµ‹è¯•æ¶ˆæ¯
        test_prompt = """
        è¯·ä¸ºPythonåˆå­¦è€…åˆ¶å®šä¸€ä¸ª2å°æ—¶çš„å­¦ä¹ è®¡åˆ’ï¼ŒåŒ…å«ä»¥ä¸‹å†…å®¹ï¼š
        1. å­¦ä¹ ç›®æ ‡ï¼ˆ3ä¸ªï¼‰
        2. å…·ä½“å†…å®¹å®‰æ’
        3. å®è·µç»ƒä¹ 

        è¯·ç”¨ä¸­æ–‡å›ç­”ï¼Œä¿æŒç®€æ´å®ç”¨ã€‚
        """

        messages = [HumanMessage(content=test_prompt)]
        print("\næ­£åœ¨è°ƒç”¨ DeepSeek API...")
        response = await llm.ainvoke(messages)

        print("\n=== DeepSeek å›å¤ ===")
        print(response.content)
        print("\nâœ“ DeepSeek API æµ‹è¯•æˆåŠŸ!")

        return True

    except Exception as e:
        print(f"\nâœ— DeepSeek API æµ‹è¯•å¤±è´¥: {str(e)}")
        return False


if __name__ == "__main__":
    success = asyncio.run(test_simple())
    if success:
        print("\nğŸ‰ DeepSeek API é…ç½®å®Œæˆä¸”å·¥ä½œæ­£å¸¸!")
    else:
        print("\nâŒ DeepSeek API é…ç½®å­˜åœ¨é—®é¢˜")